# Neurona artificial básica

Este ejemplo ilustra el funcionamiento de una neurona artificial simple,
mostrando cómo se combinan entradas, pesos y sesgo, y cómo se aplica una
función de activación.

## Descripción
Se utilizan tres valores de entrada, a los cuales se les asignan pesos
específicos. El resultado del producto punto se ajusta con un sesgo y se
procesa mediante la función de activación ReLU (Rectified Linear Unit).

Este tipo de ejemplo es útil para comprender los fundamentos de las redes
neuronales y la lógica detrás de modelos más complejos.

## Componentes
- Entradas (x)
- Pesos (w)
- Sesgo (b)
- Función de activación ReLU

## Objetivo pedagógico
Facilitar la comprensión de los conceptos básicos de la Inteligencia
Artificial antes de abordar modelos y librerías de mayor nivel.

## Ejecución
```bash
python neurona_basica.py
